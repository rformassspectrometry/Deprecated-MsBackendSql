---
title: "Description and usage of MsBackendSqlDb"
output: 
    BiocStyle::html_document:
        toc_float: true
vignette: >
    %\VignetteIndexEntry{Description and usage of MsBackendSqlDb}
    %\VignetteEngine{knitr::rmarkdown}
    %\VignetteEncoding{UTF-8}
    %\VignettePackage{MsBackendSql}
    %\VignetteDepends{Spectra,mzR,BiocStyle,msdata,magrittr}
---


```{r style, echo = FALSE, results = 'asis', message = FALSE}
BiocStyle::markdown()
```

**Package**: `r Biocpkg("MsBackendSql")`<br />
**Authors**: `r packageDescription("MsBackendSql")[["Author"]]  `<br />
**Last modified:** `r file.info("MsBackendSqlDb.Rmd")$mtime`<br />
**Compiled**: `r date()`


# Introduction

This vignette will briefly introduce the usage of new SQLite-based
backend `MsBackendSqlDb`. I will also compare `MsBackendSqlDb` to
other backends to illustrate similarities and differences.

# Usage

Firstly, we load the relevant packages:

```{r env, message = FALSE}
library("Spectra")
library("RSQLite")
library("msdata")
library("MsBackendSql")
library("magrittr")
```

# Creating `Spectra` objects with an `MsBackendSqlDb` backend

We will use a small sciex to create the backend objects.

```{r backend-df, message = FALSE}
fls <- dir(system.file("sciex", package = "msdata"), full.names = TRUE)
sp_mzr <- Spectra(fls, backend = MsBackendMzR())
sp_mzr
```

For `MsBackendSqlDb` backend, we can choose either to create a `connection`
object or to use the internal embedded `connection` object with a path in
`tempdir()` to initialize a `Spectra` instance. In the following example, 
we will create a `Spectra` object with a new `MsBackendSqlDb` backend. Usually, 
SQLite allows at most one writer to proceed concurrently, hence we will 
use non-parallel execution to create the new `Spectra` object:

```{r backend-sql}
conn <- dbConnect(SQLite(), "msdata.db")
sp_sql <- Spectra(fls, backend = MsBackendSqlDb(), 
                  dbcon = conn,
                  BPPARAM = SerialParam())
sp_sql
```

Can we load the mz and intensity values from the both backends?

```{r comp-mz}
mz1 <- mz(sp_mzr)
mz2 <- mz(sp_sql)
identical(mz1, mz2)
```


```{r comp-int}
intensity1 <- intensity(sp_mzr)
intensity2 <- intensity(sp_sql)
identical(intensity1, intensity2)
```

Now we want to check the subsetting functions:

```{r comp-subset}
sp_mzr[6:20]
sp_sql[6:20]
```

Below, we reproduce the example from the `Spectra` vignette, where
spectra originating from the second file and acquired between 175 and
189 seconds are retained:


```{r filtering-mzr}
sp_mzr %>%
    filterDataOrigin(normalizePath(fls[2])) %>%
    filterRt(c(175, 189))
```


```{r filtering-sql}
sp_sql %>%
    filterDataOrigin(normalizePath(fls[2])) %>%
    filterRt(c(175, 189))
```

If we want to revert the filtering operations on the `Spectra` instance with a
`MsBackendSqlDb` backend, we can also use `reset` function:

```{r reset}
subset_sp <- sp_sql %>%
                 filterDataOrigin(normalizePath(fls[2])) %>%
                 filterRt(c(175, 189))
reset_sp <- reset(subset_sp)
reset_sp
```

If we now compare the memory footprint of the `Spectra` objects with
the respective backends. `sp_mzr` uses the `MsBackendMzR` backend that
stored the metadata in memory, and accessed the raw data (m/z and
intensities) on demand directly in the `mzML` files.

```{r}
print(object.size(sp_mzr), units = "Kb")
```

`sp_sql` uses the `MsBackendSqlDb` backend that stored neither in
memory. The metadata and the raw data are stored in a SQLite file
(`msdata.db` defined above), and thus further minimses the memory
footprint.

```{r}
print(object.size(sp_sql), units = "Kb")
```

Both these backends are implemented to minimise memory usage, as
opposed to a full in-memory backend that stores all data and metadata
in RAM:

```{r}
sp_df <- setBackend(sp_sql, MsBackendDataFrame())
print(object.size(sp_df), units = "Mb")
```

We can also create a merged `Spectra` object by using several
small `MsBackendSqlDb` backends. Firstly, we can create 2 distinct
`Spectra` instances with `MsBackendMzR` backends:

```{r merge-sql1}
sp_mzr1 <- sp_mzr %>% filterDataOrigin(normalizePath(fls[1]))
sp_mzr2 <- sp_mzr %>% filterDataOrigin(normalizePath(fls[2]))
```

We switch the backends to `MsBackendSqlDb`:

```{r merge-sql2}
sp_sql1 <- setBackend(sp_mzr1, MsBackendSqlDb())
sp_sql2 <- setBackend(sp_mzr2, MsBackendSqlDb())
```
Now we want to merge these 2 smaller `Spectra` objects into one
`Spectra` object with `MsBackendSqlDb` backend:

```{r merge-sql3}
mergedBackendSql <- backendMerge(sp_sql1@backend, sp_sql2@backend)
sp_sql_merged <- Spectra(backend = mergedBackendSql)
sp_sql_merged
```
The merged `Spectra` object has its SQLite database file in the 
`tempdir()` directory.

```{r merge-sql4}
identical(sp_sql_merged$mz, sp_sql$mz)
identical(sp_sql_merged$intensity, sp_sql$intensity)
identical(sp_sql_merged$dataOrigin, sp_sql$dataOrigin)
```
The `MsBackendSqlDb` also provides writing functionality to users:

```{r write-sql1}
sp_sql_merged$dataOrigin <- rep("DDUV", length(sp_sql_merged))
print(unique(sp_sql_merged$dataOrigin))
```

# Session information

```{r}
sessionInfo()
```
